import numpy as np
from sklearn.linear_model import LinearRegression,Lasso,Ridge
import pickle

value = [1.73247256, 1.74997229, 1.76764877, 1.78550381, 1.8035392, 1.87752102,
         1.85874581, 1.84015835, 1.82175677, 1.8035392, 1.74997229, 1.76764877,
         1.78550381, 1.8035392, 1.82175677, 0.88638487, 1.87752102, 1.85874581,
         1.84015835, 1.82175677, 1.76764877, 1.78550381, 1.8035392, 1.82175677,
         1.84015835, 1.85874581, 1.87752102, 1.85874581, 1.84015835, 1.82175677,
         1.8035392, 1.74997229, 1.76764877, 1.78550381, 1.8035392, 1.82175677,
         1.85874581, 1.84015835, 1.82175677, 1.8035392, 1.78550381, 1.73247256,
         1.74997229, 1.76764877, 1.78550381, 1.8035392, 1.84015835, 1.82175677,
         1.8035392, 1.78550381, 1.76764877, 1.73247256, 1.82175677, 1.8035392,
         1.78550381, 1.76764877, 1.74997229, 1.69799636, 1.71514784, 1.69799636,
         1.6810164, 1.66420623, 1.76764877, 1.6810164, 1.69799636, 1.6810164,
         1.66420623, 1.64756417, 1.71514784, 1.73247256, 1.74997229, 1.73247256,
         1.71514784, 1.66420623, 1.6810164, 1.66420623, 1.64756417, 1.63108853,
         1.69799636, 1.71514784, 1.73247256, 1.71514784, 1.69799636, 1.64756417,
         1.66420623, 1.64756417, 1.63108853, 1.64756417, 1.66420623, 1.6810164,
         1.69799636, 1.71514784, 1.69799636, 1.6810164, 1.63108853, 1.64756417,
         1.63108853, 1.61477764, 1.63108853, 1.66420623, 1.6810164, 1.69799636,
         1.6810164, 1.66420623, 0.91351725, 0.92274469, 0.91351725, 0.90438208,
         0.89533825, 0.87752102, 0.86874581, 0.86005835, 0.85145777, 0.84294319,
         0.92274469, 0.93206535, 0.92274469, 0.91351725, 0.90438208, 0.88638487,
         0.87752102, 0.86874581, 0.86005835, 0.85145777, 0.93206535, 0.94148015,
         0.93206535, 0.92274469, 0.91351725, 0.90438208, 0.89533825, 0.88638487,
         0.87752102, 0.86874581, 0.86005835, 0.94148015, 0.95099005, 0.94148015,
         0.93206535, 0.92274469, 0.88638487, 0.87752102, 0.88638487, 0.87752102,
         0.86874581, 0.95099005, 0.96059601, 0.95099005, 0.94148015, 0.93206535,
         0.87752102, 0.88638487, 0.89533825, 0.88638487, 0.87752102, 0.970299,
         0.88638487, 0.89533825, 0.90438208, 0.89533825, 0.88638487, 0.970299,
         0.9801, 0.99, 1., 0.99, 0.91351725, 0.9801,
         0.99, 1., 0.99, 1., 0.94148015, 0.93206535,
         0.92274469, 0.91351725, 0.90438208, 0.970299, 0.9801, 0.99,
         1., 0.99, 0.95099005, 0.94148015, 0.93206535, 0.92274469,
         0.91351725, 0.96059601, 0.970299, 0.9801, 0.99, 0.9801,
         0.970299, 0.96059601, 0.95099005, 0.94148015, 0.93206535, 0.92274469,
         0.95099005, 0.96059601, 0.970299, 0.9801, 0.970299, 0.95099005,
         0.94148015, 0.93206535, 0.92274469, 0.91351725]
value = np.array(value)
feature = np.zeros((208, 105))
# feature = np.ones((208, 105))*0.5
for i in range(208):
    feature[i, i % 104] = 1
    feature[i, 104] = i//104

# feature = pickle.load(open("feature_map.pkl","rb"))
# feature = feature.reshape(208,-1)

clf = LinearRegression()
# clf = Lasso(alpha=1e-5)
# clf = Ridge(alpha=1)
clf.fit(feature, value)

print("coeff")
print(clf.coef_)  # 获取训练会的线性函数X参数的权值
# print(clf.get_params())  # 获取训练会的线性函数X参数的权值
print("predicted")
print(clf.predict(feature))  # 根据输出值进行预测
print("mean squared error")
print(np.mean((clf.predict(feature) - value)**2))
